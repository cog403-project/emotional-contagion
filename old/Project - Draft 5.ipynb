{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shlex\n",
    "import os.path\n",
    "import sys\n",
    "import pickle\n",
    "import datetime\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Senti Strength Program and Data Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentiStrengthLocation = \"\" #The location of SentiStrength on your computer\n",
    "SentiStrengthLanguageFolder = \"\" #The location of the unzipped SentiStrength data files on your computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Check for Senti Strength (from Senti Strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(SentiStrengthLocation):\n",
    "    print(\"SentiStrength not found at: \", SentiStrengthLocation)\n",
    "if not os.path.isdir(SentiStrengthLanguageFolder):\n",
    "    print(\"SentiStrength data folder not found at: \", SentiStrengthLanguageFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Senti Strength Helper Function (from Senti Strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RateSentiment(sentiString):\n",
    "    #open a subprocess using shlex to get the command line string into the correct args list format\n",
    "    p = subprocess.Popen(shlex.split(\"java -jar '\" + SentiStrengthLocation + \"' stdin sentidata '\" + SentiStrengthLanguageFolder + \"'\"),stdin=subprocess.PIPE,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    #communicate via stdin the string to be rated. Note that all spaces are replaced with +\n",
    "    #Can't send string in Python 3, must send bytes\n",
    "    b = bytes(sentiString.replace(\" \",\"+\"), 'utf-8')\n",
    "    stdout_byte, stderr_text = p.communicate(b)\n",
    "    #convert from byte\n",
    "    stdout_text = stdout_byte.decode(\"utf-8\") \n",
    "    #remove the tab spacing between the positive and negative ratings. e.g. 1    -5 -> 1 -5\n",
    "    stdout_text = stdout_text.rstrip().replace(\"\\t\",\" \")\n",
    "    return stdout_text + \" \" + sentiString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_users(tweets):\n",
    "\n",
    "    list_of_user = []\n",
    "\n",
    "    for tweet in tweets:\n",
    "        user_id = tweet.user.id\n",
    "        if user_id not in list_of_user:\n",
    "            list_of_user.append(user_id)\n",
    "\n",
    "    return list_of_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_tweet(tweets, end_time, time_bound):\n",
    "   \n",
    "    time_limit = datetime.timedelta(hours=time_bound)\n",
    "    lower_bound = end_time - time_limit\n",
    "    tweet_return = {}\n",
    "    \n",
    "    for user in tweets:\n",
    "        \n",
    "        friend_tweets = tweets[user]\n",
    "        \n",
    "        for tweet in friend_tweets:\n",
    "        \n",
    "            tweet_created = tweet.created_at\n",
    "\n",
    "            if end_time >= tweet_created >= lower_bound:\n",
    "                tweet_id = tweet.id\n",
    "                tweet_return[tweet_id] = tweet\n",
    "            \n",
    "    return tweet_return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Tweet and Related Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of all the \".p\" files\n",
    "directory = \"\" \n",
    "# Where you want to save the coverted files\n",
    "test_directory = \"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets output from the function, get_inital_tweets\n",
    "initial_tweets = pickle.load(open(\"\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion from Old Format to New Format - ONLY REQUIRED IF YOU USED THE OLD CODE AND HAVE the \"temp.p\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert = pickle.load(open(\"L:/Users/Daniel/Documents/2020-2021/2021 Winter Courses/COG403/Assignments/Project/Python Tweets/temp.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting user 1 of 7\n",
      "Converting user 1 of 7\n",
      "Converting user 1 of 7\n",
      "Converting user 1 of 7\n",
      "Converting user 1 of 7\n",
      "Converting user 1 of 7\n",
      "Converting user 1 of 7\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "for user in convert:\n",
    "    print(\"Converting user \" + str(index) + \" of \" + str(len(convert)))\n",
    "    index += 1\n",
    "    \n",
    "    user_id = user\n",
    "    file_name = test_directory + str(user_id) + '.p'\n",
    "    friend_info = convert[user]\n",
    "    \n",
    "    pickle.dump(friend_info, open(file_name, \"wb\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine Sentiment of Initial Tweets and Related Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing user 1 of 300\n",
      "Analyzing 60 tweets\n",
      "Analyzing 75 related tweets\n"
     ]
    }
   ],
   "source": [
    "# TODO - Convert to helper function\n",
    "sentiment_for_tweet = {}\n",
    "average_sentiment_for_tweet = {}\n",
    "\n",
    "data_analyzed = {}\n",
    "index = 1\n",
    "\n",
    "# Analyze all the  users in initial_tweets\n",
    "for t in initial_tweets:\n",
    "    print('Analyzing user ' + str(index) + \" of \" + str(len(initial_tweets)))\n",
    "    index += 1\n",
    "    \n",
    "    tweets = initial_tweets[t]\n",
    "    print(\"Analyzing \" + str(len(tweets['tweets'])) + \" tweets\")\n",
    "    \n",
    "    # Every user have a set of tweets, analyze all of them and return sentiment\n",
    "    for tweet in tweets['tweets']:\n",
    "        #print(tweet)\n",
    "        # Tweet info\n",
    "        user_id = tweet.user.id\n",
    "        tweet_id = tweet.id\n",
    "        time_created = tweet.created_at\n",
    "        tweet_text = tweet.full_text\n",
    "        file_name = directory + str(user_id) + '.p'\n",
    "\n",
    "        # Sentiment for original tweet\n",
    "        sentiment = RateSentiment(tweet_text)[:4].split()\n",
    "        sentiment = [int(sentiment[0]), int(sentiment[1])]\n",
    "        combined = sentiment[0] + sentiment[1]\n",
    "        sentiment_for_tweet[tweet_id] = {'sentiment': sentiment}\n",
    "        sentiment_for_tweet[tweet_id]['combined'] = combined\n",
    "        sentiment_for_tweet[tweet_id]['user'] = user_id\n",
    "\n",
    "        average_sentiment_for_tweet[tweet_id] = {'sentiment': sentiment}\n",
    "        average_sentiment_for_tweet[tweet_id]['combined'] = combined\n",
    "        \n",
    "        # If we have scapped the data from Twitter, analyze this tweet, otherwise, skip it\n",
    "        if os.path.exists(file_name):\n",
    "            if user_id not in data_analyzed:\n",
    "                data_analyzed[user_id] = []\n",
    "\n",
    "            data_analyzed[user_id].append(tweet_id)\n",
    "            \n",
    "            # Get tweets that are posted at most one hour before this tweet (known as related tweets throughout the code)\n",
    "            friend_tweets = pickle.load(open(file_name, \"rb\"))\n",
    "            related_friend_tweets = get_related_tweet(friend_tweets, time_created, 1)\n",
    "\n",
    "            if 'friend' not in sentiment_for_tweet[tweet_id]:\n",
    "                sentiment_for_tweet[tweet_id]['friend'] = {}\n",
    "\n",
    "            total_sentiment = []\n",
    "            print(\"Analyzing \" + str(len(related_friend_tweets)) + \" related tweets\")\n",
    "            \n",
    "            # Get the sentiment for all related tweets\n",
    "            for f in related_friend_tweets:\n",
    "                f_tweet = related_friend_tweets[f]\n",
    "                f_tweet_id = f_tweet.id\n",
    "                f_tweet_text = f_tweet.full_text\n",
    "\n",
    "                f_sentiment = RateSentiment(f_tweet_text)[:4].split()\n",
    "                f_sentiment = [int(f_sentiment[0]), int(f_sentiment[1])]\n",
    "                f_combined = f_sentiment[0] + f_sentiment[1]\n",
    "                total_sentiment.append(f_combined)\n",
    "\n",
    "                sentiment_for_tweet[tweet_id]['friend'][f_tweet_id] = {'sentiment': sentiment}\n",
    "                sentiment_for_tweet[tweet_id]['friend'][f_tweet_id]['combined'] = f_combined\n",
    "\n",
    "\n",
    "            average_s = sum(total_sentiment)/len(total_sentiment)\n",
    "            average_sentiment_for_tweet[tweet_id]['friend'] = average_s\n",
    "            \n",
    "        # Periodically save the result\n",
    "        pickle.dump(sentiment_for_tweet, open(\"sentiment.p\", \"wb\"))\n",
    "        pickle.dump(average_sentiment_for_tweet, open(\"avg_sentiment.p\", \"wb\"))\n",
    "        pickle.dump(data_analyzed, open(\"data_analyzed.p\", \"wb\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work In Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
